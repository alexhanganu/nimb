import shutil
from os import system, path, listdir, environ, remove
from distribution.utilities import ErrorMessages, makedir_version2
from distribution.setup_miniconda import setup_miniconda
from distribution.setup_freesurfer import SETUP_FREESURFER

from distribution.check_disk_space import *
from distribution import SSHHelper

# -- for logging, instead of using print --
logger = logging.getLogger(__name__)
logging.basicConfig(format='%(asctime)s %(module)s %(levelname)s: %(message)s')
logger.setLevel(logging.DEBUG)
# --

class DistributionHelper():

    def __init__(self, credentials_home, projects, locations, installers, projec
        self.NIMB_HOME = locations["local"]["NIMB_PATHS"]["NIMB_HOME"]
        self.NIMB_tmp = locations["local"]["NIMB_PATHS"]["NIMB_tmp"]
        self.locations = locations # Æ°local, remote] json configuration
        self.projects = projects # project.json
        self.credentials_home = credentials_home
        self.project_name = project
        self.installers = installers

        # self.var = Get_Vars().get_default_vars()
        self.user_name, self.user_password = self.get_username_password_cluster_from_sqlite()
        # setup folder
        self.setup_folder = "../setup"
        self.git_repo = "https://github.com/alexhanganu/nimb"

    def get_username_password_cluster_from_sqlite(self):
        """
        get user name and password from sqlite database
        :return: username, password in string
        """
        try:
            clusters = database._get_Table_Data('Clusters', 'all')
            user_name = clusters[list(clusters)[0]]['Username']
            user_password = clusters[list(clusters)[0]]['Password']
            if len(user_name) < 1 or len(user_password) < 1:
                ErrorMessages.password()
            return user_name, user_password
        except TypeError:
            return 'none', 'none'



    def is_setup_vars_folders(self,is_freesurfer_nim=False,
                              is_nimb_classification=False,
                              is_nimb_fs_stats=False):
        """
        check if those variables are defined in json or not
        for example check NIMB_PATHS exists in the local.json
        :param config_file: path to configuration json file
        :param is_freesurfer_nim: True if run nimb freesurfer
        :param is_nimb_classification:
        :param is_nimb_fs_stats:
        :return: True if there is no error, otherwise, return False
        """
        # check path exisits and create path if needed
        self.verify_paths()

        if is_nimb_classification or is_freesurfer_nim:
            if "NIMB_PATHS" not in self.locations['local'].keys():
                logger.fatal("NIMB_PATHS is missing")
                # sys.exit()
                return False
            for key, val in self.locations['local']:
                if len(val) < 1:
                    logger.fatal(f"{key} is missing")
                    return False
        if is_nimb_fs_stats:
            if "STATS_PATHS" not in self.locations['local'].keys():
                ErrorMessages.error_stat_path()
                return False
            if "STATS_HOME" not in self.locations['local']['STATS_PATHS']:
                ErrorMessages.error_stat_path()
                return False

        if self.locations['local']['FREESURFER']['FreeSurfer_install'] == 1:
            if len(self.locations['local']['FREESURFER']['FREESURFER_HOME']) < 1:
                logger.fatal("FREESURFER_HOME is missing.")
                return False
            if "MRDATA_PATHS" not in self.locations['local'].keys():
                logger.fatal("MRDATA_PATHS is missing.")
                return False
        return True
    def ready(self):
        """
        verify if NIMB is ready to be used
        :return: bool
        """
        ready = True
        if not self.classify_ready():
            ErrorMessages.error_classify()
            ready = False
        else:
            print("NIMB ready to perform classification")
        if not self.fs_ready():
            ErrorMessages.error_fsready()
            ready = False
        else:
            print("NIMB ready to perform FreeSurfer processing")
        return ready

    def classify_ready(self):
        ready = True
        for p in (self.locations['local']['NIMB_PATHS']['NIMB_NEW_SUBJECTS'],
                  self.NIMB_HOME,self.NIMB_tmp):
            if not path.exists(p):
                try:
                    # if path start with ~
                    makedir_version2(p)
                except Exception as e:
                    print(e)
            if not path.exists(p):
                ready = False
                break
        return ready

    def exisit_or_created(self, folder_name):
        if not os.path.exists(folder_name):
            os.mkdir(folder_name)

    def fs_ready(self):
        if self.locations['local']['FREESURFER']['FreeSurfer_install'] == 1:
            if self.check_freesurfer_ready():
                return self.fs_chk_fsaverage_ready()
        else:
            return False

    def fs_chk_fsaverage_ready(self):
        if not path.exists(path.join(self.locations['local']['FREESURFER']['FS_SUBJECTS_DIR'],'fsaverage', 'xhemi')):
            print('fsaverage or fsaverage/xhemi is missing from SUBJECTS_DIR: {}'.format(self.locations['local']['FREESURFER']['FS_SUBJECTS_DIR']))
            return False
        else:
            return True

    def verify_paths(self):
        # to verify paths and if not present - create them or return error
        if path.exists(self.locations['local']['NIMB_PATHS']['NIMB_HOME']):
            for p in (     self.NIMB_tmp,
                 path.join(self.NIMB_tmp, 'mriparams'),
                 path.join(self.NIMB_tmp, 'usedpbs'),
                           self.locations['local']['NIMB_PATHS']['NIMB_NEW_SUBJECTS'],
                           self.locations['local']['NIMB_PATHS']['NIMB_PROCESSED_FS'],
                           self.locations['local']['NIMB_PATHS']['NIMB_PROCESSED_FS_error']):
                if not path.exists(p):
                    print('creating path ',p)
                    makedir_version2(p)
        if path.exists(self.locations['local']['FREESURFER']['FREESURFER_HOME']):
            if not path.exists(self.locations['local']['FREESURFER']['FS_SUBJECTS_DIR']):
                    print('creating path ',p)
                    makedir_version2(self.locations['local']['FREESURFER']['FS_SUBJECTS_DIR'])
                    system("cp -r"+path.join(self.locations['local']['FREESURFER']['FREESURFER_HOME'], "subjects", "fsaverage")+" "+self.vars['local']['FREESURFER']['FS_SUBJECTS_DIR'])
    # UNITE until here
    # =========================================

    def get_project_vars(self, var_name, project):
        """
        get the PROCESSED_FS_DIR
        :param config_file:
        :var_name: like PROCESSED_FS_DIR
        :return: empty string, or values
        """
        # PROJECT_DATA
        if project not in self.projects.keys():
            print("There is no path for project: "+project+" defined. Please check the file: "+path.join(self.credentials_home, "projects.json"))
            return ""
        return self.projects[project][var_name]

    def get_PROCESSED_FS_DIR(self):
        """

        :return: like ["local","/home/username/database/source/mri"],
        """
        machine, path =  self.projects[self.project_name]['PROCESSED_FS_DIR']
        return machine, path

    def get_SOURCE_SUBJECTS_DIR(self):
        """

        :return: machine and path in that machine like ["local","/home/username/database/source/mri"],
        """
        machine, path =  self.projects[self.project_name]['SOURCE_SUBJECTS_DIR']
        return machine, path


    def run(self, Project):
        """
        # todo: need to find a location for this function
        :param Project:
        :return:
        """
        # 0 check the variables
        # if FreeSurfer_install = 1:
        host_name = ""
        if self.fs_ready():
            # 1. install required library and software on the local computer, including freesurfer
            self.setting_up_local_computer()
            # install freesurfer locally
            setup = SETUP_FREESURFER(self.locations,installers=self.installers)
        else:
            logger.debug("Setting up the remote server")
            # --get the name and the address of remote server
            for machine_name, machine_config in self.locations.items():
                if machine_name == 'local': # skip
                    continue
                # a. check the fs_install == 1
                if machine_config['FREESURFER']['FreeSurfer_install'] == 1:
                    host_name = self.projects['LOCATION'][machine_name]
                    self.setting_up_remote_linux_with_freesurfer(host_name=host_name)

        # continue working from below
        print("get list of un-process subject. to be send to the server")
        # must set SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR before calling: get from project
        # project name get from where?

        machine_PROCESSED_FS_DIR, PROCESSED_FS_DIR = self.get_PROCESSED_FS_DIR()
        machine_SOURCE_SUBJECTS_DIR, SOURCE_SUBJECTS_DIR = self.get_SOURCE_SUBJECTS_DIR()

        # DistributionHelper.get_list_subject_to_be_processed_remote_version(SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR)
        # DistributionHelper.get_list_subject_to_be_processed_remote_version(remote_host=host_name,PROCESSED_FS_DIR=)
        # how this part work?
        # status.set('Copying data to cluster ')
        logger.debug('Copying data to cluster ')
        #  copy subjects to cluster
        self.run_copy_subject_to_cluster(Project)
        # status.set('Cluster analysis started')
        # status.set("Cluster analysing running....")
        logger.debug('Cluster analysis started')
        logger.debug("Cluster analysing running....")
        self.run_processing_on_cluster_2()


    def run_processing_on_cluster_2(self):
        '''
        execute the python a/crun.py on the remote cluster
        :return:
        '''
        # version 2: add username, password, and command line to run here
        clusters = database._get_Table_Data('Clusters', 'all')

        # project_folder = clusters[list(clusters)[0]]['HOME']
        cmd_run = " python a/crun.py -submit false" #submit=true
        load_python_3 = 'module load python/3.7.4;'
        cmd_run_crun_on_cluster = load_python_3 +"cd " + "/home/hvt/" + "; " + cmd_run
        print("command: "+ cmd_run_crun_on_cluster)
        host_name = clusters[list(clusters)[0]]['remote_address'] #

        print("Start running the the command via SSH in cluster: python a/crun.py")
        SSHHelper.running_command_ssh_2(host_name=host_name, user_name=self.user_name,
                                    user_password=self.user_password,
                                    cmd_run_crun_on_cluster=cmd_run_crun_on_cluster)

    def run_copy_subject_to_cluster(Project):
        '''
        copy the subjects from subject json file to cluster
        :param Project: the json file of that project
        :return: None
        '''
        # todo: how to get the active cluster for this project

        clusters = database._get_Table_Data('Clusters', 'all')
        cname = [*clusters.keys()][0]
        project_folder = clusters[cname]['HOME']
        a_folder = clusters[cname]['App_DIR']
        subjects_folder = clusters[cname]['Subjects_raw_DIR']
        # the json path is getting from mri path,
        mri_path = database._get_Table_Data('Projects', Project)[Project]['mri_dir']
        print(mri_path)
        print("subject json: " + mri_path)
        SSHHelper.copy_subjects_to_cluster(mri_path, subjects_folder, a_folder)


    def check_freesurfer_ready(self):
        """
        check and install freesurfer
        :return:
        """
        ready = False
        if not path.exists(path.join(self.locations['local']['FREESURFER']['FREESURFER_HOME'], "MCRv84")):
            print('FreeSurfer must be installed')
            from .setup_freesurfer import SETUP_FREESURFER
            SETUP_FREESURFER(self.locations, self.installers)
            ready = True
        else:
            print('start freesurfer processing')
            ready =  True
        return ready


    def nimb_stats_ready(self, project):
        """will check if the STATS folder is present and will create if absent
           will return the folder with unzipped stats folder for each subject"""

        if not path.exists(self.locations["local"]["STATS_PATHS"]["STATS_HOME"]):
            makedir_version2(self.locations["local"]["STATS_PATHS"]["STATS_HOME"])

        PROCESSED_FS_DIR = self.projects[project]["PROCESSED_FS_DIR"]

        if any('.zip' in i for i in listdir(PROCESSED_FS_DIR)):
            from .manage_archive import ZipArchiveManagement
            zipmanager = ZipArchiveManagement()
            tmp_dir = path.join(self.NIMB_tmp, 'tmp_subject_stats')
            if not path.exists(tmp_dir):
                makedir_version2(tmp_dir)
            zipmanager.extract_archive(PROCESSED_FS_DIR, ['stats',], tmp_dir)
            return tmp_dir
        else:
            return PROCESSED_FS_DIR
        print('perform statistical analysis')


    def fs_glm(self):

        print('start freesurfer GLM')

    def run_stats_ready(self):
        """will check if xlsx file for project is provided
           if all variables are provided
           if all paths for stats are created
           if NIMB is ready to perform statistical analysis"""
        ready = True
        if not path.exists(self.projects[self.project_name]["GLM_file_group"]):
            print("data file is missing from nimb_credentials.py/projects.json -> project")
            ready = False
        return ready

    def setting_up_local_computer(self):
        if platform.startswith('linux'):
            print("Currently only support setting up on Ubuntu-based system")
            # do the job here
            self.setting_up_local_linux_with_freesurfer()
        elif platform in ["win32"]:
            print("The system is not fully supported in Windows OS. The application quits now .")
            exit()
        else: # like freebsd,
            print("This platform is not supported")
            exit()
    def setting_up_local_linux_with_freesurfer(self):
        """
        install miniconda and require library
        :return:
        """
        setup_miniconda(self.NIMB_HOME)

    def setting_up_remote_linux_with_freesurfer(self, host_name):
        # go the remote server by ssh, enter the $HOME (~) folder
        # execute following commands
        # 0. prepare the python load the python 3.7.4
        # 1. git clone the repository to NIMB_HOME
        # 2. run the python file remote_setupv2.py
        #   a. get the remote name and address
        #   b. get the username password
        #   c. load the load python command
        #   d. connect ssh
        #   e. git clone
        #   f. setup freesurfer
        #   g. setup miniconda
        #   h. run the command to process ready
        # get the nimb_home at remote server
        load_python_3 = 'module load python/3.7.4; module load python/3.8.2;' # python 2 is okay, need to check
        cmd_git = f" cd ~; git clone {self.git_repo};  "
        cmd_install_miniconda = "python nimb/distribution/setup_miniconda.py; "
        cmd_run_setup = " cd nimb/setup; python nimb.py -process ready"

        cmd_run_crun_on_cluster = load_python_3 + cmd_git + cmd_install_miniconda + cmd_run_setup
        print("command: " + cmd_run_crun_on_cluster)
        # todo: how to know if the setting up is failed?
        print("Setting up the remote cluster")
        SSHHelper.running_command_ssh_2(host_name=host_name, user_name=self.user_name,
                                    user_password=self.user_password,
                                    cmd_run_crun_on_cluster=cmd_run_crun_on_cluster)


    # @staticmethod
    def is_all_subject_processed(self, SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR):
        """
        must be absolute path
        :param SOURCE_SUBJECTS_DIR:
        :param PROCESSED_FS_DIR:
        :return:
        """
        un_process_sj = ListSubjectHelper.get_to_be_processed_subject_local(SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR)
        if len(un_process_sj) > 0:
            return True
        return False

    # @staticmethod
    def get_list_subject_to_be_processed_local_version(self, SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR):
        """
        both SOURCE_SUBJECTS_DIR and PROCESSED_FS_DIR is inside a single computer (i.e., local pc)

        1. get the list of un-processed subject
        2. get the current available space on hard-disk of user
        2. calculate the list of
		initial script in database -> create_lsmiss
        :param SOURCE_SUBJECTS_DIR:
        :return:
        """
        # get the list of unprocessed subjects
        un_process_sj = ListSubjectHelper.get_to_be_processed_subject_local(SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR)
        un_process_sj = [os.path.join(SOURCE_SUBJECTS_DIR,file) for file in un_process_sj ]
        # based on availabe space
        to_be_process_subject = DiskspaceUtility.get_subject_to_be_process_with_free_space(un_process_sj)
        #
    @staticmethod
    def helper(ls_output):
        """
        split the outputs of 'ls' to get all file names
        :param ls_output:
        :return:
        """
        return ls_output.split("\n")[0:-1]
    # @staticmethod
    def get_list_subject_to_be_processed_remote_version(self, SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR,
                                                        remote_host, remote_username, remote_password):
        """
        use when SOURCE_SUBJECTS_DIR, PROCESSED_FS_DIR, are at two computers
        1. connect to the remote host
        2. get local process subjects
        3. get remote processed subjects
        4. get un-processs subjects from local
        5. get available space on remote computer
        6. get to-be-process subjects
        7. (other functions) send those subjects to the remote server
        :param SOURCE_SUBJECTS_DIR: MUST BE FULL PATHS
        :param PROCESSED_FS_DIR:
        :return: full path of subjects that is not process yet
        """
        ssh_session = SSHHelper.getSSHSession(remote_host, remote_username, remote_password)
        (zip_out, err) = runCommandOverSSH(ssh_session, f" cd {PROCESSED_FS_DIR}; ls *.zip") #
        (gz_out, err) = runCommandOverSSH(ssh_session, f"cd {PROCESSED_FS_DIR}; ls *.gz")
        # at remote
        all_processed_file_remote = DistributionHelper.helper(gz_out) + DistributionHelper.helper(zip_out) # only file name, no path
        # at local
        all_subjects_at_local = ListSubjectHelper.get_all_subjects(SOURCE_SUBJECTS_DIR) # full path
        all_subjects_at_local_short_name = [short_name.split("/")[-1] for short_name in all_subjects_at_local ]
        # get free space remotely
        free_space = DiskspaceUtility.get_free_space_remote(ssh_session)
        to_be_process_subject = set(all_subjects_at_local_short_name) - set(all_processed_file_remote) # not consider space yet
        # consider the space available the remote server
        free_space = min(free_space, 10*1024) # min of 'free space' and 10GB
        to_be_process_subject = DiskspaceUtility.get_subject_upto_size(free_space, to_be_process_subject)

        print("Remote server has {0}MB free, it can stored {1} subjects".format(free_space, len(to_be_process_subject)))
        ssh_session.close()
        return [os.path.join(SOURCE_SUBJECTS_DIR,subject) for subject in to_be_process_subject] # full path


    @staticmethod
    def load_configuration_json(config_file ="../setup/local.json"):
        # todo: this method is going to be abandon later: reason stop
        # using static method
        with open(config_file) as file:
            config_dict = json.load(file)
        return config_dict
    @staticmethod
    def send_subject_data(config_file ="../setup/local.json"):
        """
        copy the subject to NIMB_NEW_SUBJECTS
        it can be on local computer
        or remote compyuter
        the list of subject is get by get_list_subject_to_be_processed_local_version for local
        and get_list_subject_to_be_processed_remote_version for remote
        :param config_file:
        :return:
        """
        # read all the json configruation files
        # check if it is FreeSurfer_install
        # if is local.json
        # send to NIMB_NEW_SUBJECTS
        # if remoe
        # send to NIMB_NEW_SUBECTS, choose the first remote
        # 1. read the local configuration files
        config_dict = DistributionHelper.load_configuration_json(config_file)
        if config_dict[DistributionHelper.freesurfer]["FreeSurfer_install"] == 1:
            send_path =  config_dict['NIMB_PATHS']['NIMB_NEW_SUBJECTS']
            # copy subject to this path, using shutil
            # todo: re-test the local part
            PROCESSED_FS_DIR = DistributionHelper.get_PROCESSED_FS_DIR(config_file=config_file)
            SOURCE_SUBJECTS_DIR = DistributionHelper.get_SOURCE_SUBJECTS_DIR(config_file=config_file)
            subjects = DistributionHelper.get_list_subject_to_be_processed_local_version(SOURCE_SUBJECTS_DIR=SOURCE_SUBJECTS_DIR,
                                                                                         PROCESSED_FS_DIR=PROCESSED_FS_DIR)
            for sj in subjects:
                shutil.copy(sj,send_path)
            return send_path
        elif config_dict[DistributionHelper.freesurfer]["FreeSurfer_install"] == 0: # check on remote cluster
            if "REMOTE" not in config_dict.keys():
                print("There is no remote server!")
                return
            # 2. get the first remote cluster
            for remote_name, remote_add in config_dict['REMOTE'].items(): # get the first only
                cluster_name = remote_name
                cluster_address = remote_add
                break
            # 3. open the {cluster_name}.json
            cluster_config_dict = DistributionHelper.load_configuration_json(f"../setup/{cluster_name}.json")
            send_path = cluster_config_dict['NIMB_PATHS']['NIMB_NEW_SUBJECTS']
            # upload all files to send path
            # 1. get all the subject file path, using exisit helper method
            PROCESSED_FS_DIR = DistributionHelper.get_PROCESSED_FS_DIR(f"../setup/{cluster_name}.json")
            SOURCE_SUBJECTS_DIR = DistributionHelper.get_SOURCE_SUBJECTS_DIR(f"../setup/{cluster_name}.json")
            user_name, user_password = DistributionHelper.get_username_password_cluster_from_sqlite()
            subjects_to_send = DistributionHelper.get_list_subject_to_be_processed_remote_version(SOURCE_SUBJECTS_DIR=SOURCE_SUBJECTS_DIR,
                                                                                                  PROCESSED_FS_DIR=PROCESSED_FS_DIR,
                                                                                                  remote_host=cluster_address,
                                                                                                  remote_username=user_name,
                                                                                                  remote_password=user_password)

            ssh_session = SSHHelper.getSSHSession(remote_host=cluster_address, remote_username=user_name, remote_password=user_password)
            # call upload_multiple_files_to_cluster for them
            SSHHelper.upload_multiple_files_to_cluster(ssh_session=ssh_session,dest_folder=send_path,file_list=subjects_to_send)
            #

            return send_path
            # 4. upload the subjects to that path
    @staticmethod
    def upload_subject_to_remote(local_path, remote_path, remote_host, remote_username, remote_password):
        # call the ssh helper to upload the file
        # to NIMB_NEW_SUBJECTS
        # SSHHelper.copy_subjects_to_cluster(mri_path, subjects_folder, a_folder)
        # upload_multiple_files_to_cluster()

        raise NotImplementedError
        pass

    @staticmethod
    def check_status_of_free_surfer():
        """
        not implement yet
        :return:
        """
        raise NotImplementedError

    @staticmethod
    def download_processed_subject(local_destination, remote_path, remote_host, remote_username, remote_password):
        """
        Download from processed folder back to local
        :param local_destination: place to stored downloaded files and folders
        :param remote_path:
        :param remote_host:
        :param remote_username:
        :param remote_password:
        :return: None
        """
        ssh_session = SSHHelper.getSSHSession(remote_host, remote_username, remote_password)
        stdin, stdout, stderr = ssh_session.exec_command('ls '+path_dst)
        ls_copy = [line.strip('\n') for line in stdout]
        sftp = ssh_session.open_sftp()
        for val in ls_copy:
                    size_src = SSHHelper.get_size_on_remote(ssh_session, path.join(path_dst, val))
                    print('left to copy: ',len(ls_copy[ls_copy.index(val):]))
                    SSHHelper.download_files_from_server(ssh_session, remote_path, local_destination)
                    size_dst = path.getsize(path_src+'/'+val)
                    if size_dst == size_src:
                        print('        copy ok')
                        #SSHHelper.remove_on_remote(path.join(path_dst, val))
                    else:
                        print('copy error, retrying ...')
        ssh_session.close()


    def StopAllActiveTasks():
        from distribution.SSHHelper import delete_all_running_tasks_on_cluster
        clusters = database._get_Table_Data('Clusters', 'all')
        delete_all_running_tasks_on_cluster(
            clusters[0][1], clusters[0][2], clusters[0][5], clusters[0][3])

# if __name__ == "__main__":
    # distribution = DistributionHelper(projects,
                                               # locations,
                                               # installers)
    # #DistributionHelper.is_setup_vars_folders(is_nimb_fs_stats=True, is_nimb_classification=True, is_freesurfer_nim=True)
    # user_name,user_password = DistributionHelper.get_username_password_cluster_from_sqlite()
    # cluster = "cedar.computecanada.ca"
    # subjects = DistributionHelper.get_list_subject_to_be_processed_remote_version("/Users/van/Downloads/tmp/fs","/home/hvt/tmp2",cluster,user_name,user_password)
    # print(subjects)
    # ssh = SSHHelper.getSSHSession(cluster, user_name, user_password)
    # # download data from remote
    # download_files_from_server(ssh,SOURCE_SUBJECTS_DIR,PROCESSED_FS_DIR)
    # ssh.close()

    # # send data
    # DistributionHelper.send_subject_data(config_file=path.join(credentials_home, "projects.json"))

if __name__ == "__main__":
    d = DistributionHelper()
    if d.is_setup_vars_folders(is_freesurfer_nim=True, is_nimb_fs_stats=True, is_nimb_classification=False): # True
        pass
